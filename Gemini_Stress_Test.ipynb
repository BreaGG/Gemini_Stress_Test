{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927466bc-feb1-4a9b-bd51-f2c64165a1da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install google-generativeai\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install spacy\n",
    "# %pip install numpy\n",
    "# %pip install dotenv\n",
    "# %pip install torch\n",
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a183336a-e23d-4ed1-a9f3-f1ee8aca7e10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 66.0M  100 66.0M    0     0  15.4M      0  0:00:04  0:00:04 --:--:-- 15.5M\n",
      "chromosome1.fa already exists -- do you wish to overwrite (y or n)? "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL for Chromosome 1 in FASTA format\n",
    "url = 'ftp://ftp.ensembl.org/pub/release-105/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.1.fa.gz'\n",
    "\n",
    "# Download the file\n",
    "!curl {url} --output chromosome1.fa.gz\n",
    "\n",
    "# Unzip the file\n",
    "!gunzip chromosome1.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47522eab-8be1-4ebd-be30-b30ad83187e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the genome sequence from the FASTA file\n",
    "with open('chromosome1.fa', 'r') as file:\n",
    "    # Skip the header line\n",
    "    next(file)\n",
    "    # Read the sequence data\n",
    "    genome_sequence = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb3a4a9-c713-471c-8346-86aab8f5b203",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nucleotides (tokens): 248956422\n"
     ]
    }
   ],
   "source": [
    "token_count = len(genome_sequence)\n",
    "print(f\"Total nucleotides (tokens): {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd2a6ab-ec53-4223-b0b3-bb1b3a602b11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API key from environment variable\n",
    "api_key = os.getenv('GENAI_API_KEY')\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "generation_config = {\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"max_output_tokens\": 5000,\n",
    "}\n",
    "\n",
    "geminiModel = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt and response\n",
    "# Since the sequence is too large, let's take a segment for demonstration\n",
    "segment_length = 15000  # 15,000 nucleotides\n",
    "genome_segment = genome_sequence[:segment_length]\n",
    "\n",
    "# Update the prompt with the segment\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a genomic analyst AI specializing in identifying patterns, mutations, and areas of interest in DNA sequences.\n",
    "\n",
    "Analyze the following human genome segment from Chromosome 1 and provide insights into:\n",
    "\n",
    "- Repetitive sequences and their significance.\n",
    "- Potential gene locations and their functions.\n",
    "- Common mutations or SNPs (Single Nucleotide Polymorphisms) and their associated diseases.\n",
    "- Any notable patterns that could be of medical research interest.\n",
    "\n",
    "Genome Segment:\n",
    "{genome_segment}\n",
    "\"\"\"\n",
    "\n",
    "response = geminiModel.generate_content(prompt)\n",
    "documentation = response.text\n",
    "print(\"Response:\\n\", documentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bertModel = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to generate BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        output = bertModel(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate similarity using BERT embeddings\n",
    "def calculate_similarity_bert(text1, text2):\n",
    "    embedding1 = get_bert_embedding(text1)\n",
    "    embedding2 = get_bert_embedding(text2)\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load spaCy model for word embeddings\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function to calculate semantic similarity\n",
    "def calculate_similarity(text1, text2):\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    \n",
    "    # Convert documents to vectors\n",
    "    vector1 = doc1.vector\n",
    "    vector2 = doc2.vector\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load entailment model\n",
    "nli_model = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Function to check entailment\n",
    "def check_entailment(prompt, response):\n",
    "    result = nli_model(f\"{prompt} [SEP] {response}\")\n",
    "    label = result[0]['label']\n",
    "    score = result[0]['score']\n",
    "    if label == 'ENTAILMENT':\n",
    "        return score\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Coverage Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def keyword_coverage(prompt, response):\n",
    "    prompt_words = prompt.lower().split()\n",
    "    response_words = response.lower().split()\n",
    "    \n",
    "    prompt_word_count = Counter(prompt_words)\n",
    "    response_word_count = Counter(response_words)\n",
    "    \n",
    "    coverage = sum(min(prompt_word_count[word], response_word_count[word]) for word in prompt_word_count) / len(prompt_words)\n",
    "    return coverage\n",
    "\n",
    "coverage_score = keyword_coverage(prompt, documentation)\n",
    "print(f\"Keyword Coverage Score: {coverage_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8776 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get individual scores\u001b[39;00m\n\u001b[1;32m      6\u001b[0m similarity_score \u001b[38;5;241m=\u001b[39m calculate_similarity_bert(prompt, documentation)\n\u001b[0;32m----> 7\u001b[0m entailment_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_entailment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocumentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m coverage_score \u001b[38;5;241m=\u001b[39m keyword_coverage(prompt, documentation)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Aggregate overall coherence score\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m, in \u001b[0;36mcheck_entailment\u001b[0;34m(prompt, response)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_entailment\u001b[39m(prompt, response):\n\u001b[0;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnli_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m [SEP] \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mresponse\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     label \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     score \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[0;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/pipelines/base.py:1268\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1261\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/pipelines/base.py:1275\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1274\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1275\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/pipelines/base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1802\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[0;32m-> 1802\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1510\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1507\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1062\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m-> 1062\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1065\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:116\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    111\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    112\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    113\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    114\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GeminiStressTest/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "def aggregate_coherence_score(similarity_score, entailment_score, coverage_score):\n",
    "    # Weighted sum of different metrics\n",
    "    return 0.5 * similarity_score + 0.3 * entailment_score + 0.2 * coverage_score\n",
    "\n",
    "# Get individual scores\n",
    "similarity_score = calculate_similarity_bert(prompt, documentation)\n",
    "entailment_score = check_entailment(prompt, documentation)\n",
    "coverage_score = keyword_coverage(prompt, documentation)\n",
    "\n",
    "# Aggregate overall coherence score\n",
    "overall_coherence_score = aggregate_coherence_score(similarity_score, entailment_score, coverage_score)\n",
    "print(f\"Overall Coherence Score: {overall_coherence_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.89\n",
      "Coherence Score: 0.75\n",
      "The response is coherent with the prompt.\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the coherence score\n",
    "similarity_score_bert = calculate_similarity_bert(prompt, documentation)\n",
    "print(f\"Coherence Score: {similarity_score_bert:.2f}\")\n",
    "\n",
    "similarity_score = calculate_similarity(prompt, documentation)\n",
    "print(f\"Coherence Score: {similarity_score:.2f}\")\n",
    "\n",
    "# Set a threshold for coherence (you can adjust this based on experimentation)\n",
    "threshold = 0.7\n",
    "if similarity_score >= threshold:\n",
    "    print(\"The response is coherent with the prompt.\")\n",
    "else:\n",
    "    print(\"The response may lack coherence with the prompt. Consider reviewing the output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " ## Reinforcement Learning: Learning by Doing\n",
      "\n",
      "Reinforcement learning (RL) is a type of machine learning where an **agent** learns to interact with its **environment** to achieve a **goal**. This learning process is achieved by receiving **rewards** for taking actions that lead to desired outcomes and **penalties** for taking actions that lead to undesirable outcomes. \n",
      "\n",
      "Think of it like training a dog. You give the dog a treat (reward) when it performs a desired action, like sitting. You might scold the dog (penalty) if it jumps on the couch. Through this process of trial and error, the dog learns to associate certain actions with rewards and others with penalties, leading to desired behavior.\n",
      "\n",
      "Here's a breakdown of key concepts:\n",
      "\n",
      "**1. Agent:** This is the learner, the AI system that interacts with the environment. It can be anything from a robot to a software program.\n",
      "\n",
      "**2. Environment:** This is the world the agent operates in. It can be a physical space, a simulated world, or even a complex abstract problem.\n",
      "\n",
      "**3. Actions:** These are the choices the agent can take within the environment. For example, a robot arm can move up, down, left, or right.\n",
      "\n",
      "**4. State:** This represents the current situation the agent is in. It can be a simple description of the environment or a complex set of data.\n",
      "\n",
      "**5. Reward:** This is the feedback the agent receives after taking an action. Positive rewards encourage the agent to repeat actions that lead to desirable outcomes. Negative rewards (penalties) discourage actions that lead to undesirable outcomes.\n",
      "\n",
      "**6. Goal:** This is the desired outcome the agent is trying to achieve. It can be something specific, like winning a game, or more general, like maximizing its cumulative reward.\n",
      "\n",
      "**The RL process:**\n",
      "\n",
      "1. **Initialization:** The agent starts in a specific state.\n",
      "2. **Action selection:** The agent chooses an action based on its current knowledge of the environment and its goal.\n",
      "3. **State transition:** The environment changes based on the action taken by the agent, leading to a new state.\n",
      "4. **Reward:** The agent receives a reward based on the new state.\n",
      "5. **Learning:** The agent uses the reward to update its knowledge about the environment and its actions, making better choices in the future.\n",
      "\n",
      "**Types of Reinforcement Learning:**\n",
      "\n",
      "* **Model-based:** The agent builds a model of the environment to predict the consequences of its actions.\n",
      "* **Model-free:** The agent learns directly from experience without building an explicit model of the environment.\n",
      "\n",
      "**Applications of Reinforcement Learning:**\n",
      "\n",
      "* **Robotics:** Training robots to perform complex tasks, like navigating a warehouse or assembling products.\n",
      "* **Gaming:** Developing AI agents that can play games at a superhuman level, like chess or Go.\n",
      "* **Finance:** Optimizing trading strategies and managing investment portfolios.\n",
      "* **Healthcare:** Developing personalized treatment plans and improving disease diagnosis.\n",
      "\n",
      "**Challenges of Reinforcement Learning:**\n",
      "\n",
      "* **Exploration vs. Exploitation:** The agent needs to balance exploring new actions to find better solutions and exploiting known actions to maximize its immediate reward.\n",
      "* **High dimensionality:** Real-world environments often have a large number of states and actions, making it challenging for the agent to learn effectively.\n",
      "* **Sparse rewards:** In some cases, rewards are only given after a long sequence of actions, making it difficult for the agent to learn.\n",
      "\n",
      "Overall, reinforcement learning is a powerful tool for solving complex problems where a clear goal and feedback mechanism are available. It allows agents to learn from experience and adapt to changing environments, making it a promising technology for various applications.\n",
      "\n",
      "Coherence Score: 0.59\n",
      "The response may lack coherence with the prompt. Consider reviewing the output.\n"
     ]
    }
   ],
   "source": [
    "# Prompt and response\n",
    "prompt = \"Explain the concept of reinforcement learning.\"\n",
    "response = geminiModel.generate_content(prompt)\n",
    "documentation = response.text\n",
    "print(\"Response:\\n\", documentation)\n",
    "\n",
    "# Calculate and print the coherence score\n",
    "similarity_score = calculate_similarity_bert(prompt, documentation)\n",
    "print(f\"Coherence Score: {similarity_score:.2f}\")\n",
    "\n",
    "# Set a threshold for coherence (you can adjust this based on experimentation)\n",
    "threshold = 0.7\n",
    "if similarity_score >= threshold:\n",
    "    print(\"The response is coherent with the prompt.\")\n",
    "else:\n",
    "    print(\"The response may lack coherence with the prompt. Consider reviewing the output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(['Prompt to Output'], [similarity_score], color='blue')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Comparison')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.title('Coherence Score between Prompt and Output')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2bdc5fc7-7025-4f1d-9388-06a53d99004c",
     "origId": 3288467045714575,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gemini Stress Test",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "GeminiStressTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
